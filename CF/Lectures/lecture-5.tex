\chapter{Lecture 5: 26/09}

\section{Merton Model: Matlab implementation}
Just like we did for the Kou model, we will now implement a Matlab function to
simulate the Merton model.
Recall that in the Merton model the L\'evy process $X_t$ is given by:
\[ X_t = \gamma t + \sigma W_t + \sum_{i=1}^{N_t} Y_i \]
where $W_t$ is a standard Brownian motion, $N_t$ is a Poisson process with
intensity $\lambda$, and $Y_i$ are i.i.d. random variables with distribution
$\mathcal{N}(\mu_J, \sigma_J^2)$ independent of $W_t$ and $N_t$.
Hence we have to take in the following model and simulation parameters:
\begin{itemize}
    \item $N_{sim}$: the number of simulations to run.
    \item $T$: the time horizon.
    \item $M$: the number of time steps.
    \item Model parameters: $\sigma, \lambda, \mu_J, \sigma_J$.
\end{itemize}
Let us note that we have one less parameter than in the Kou model.
The characteristic exponent of the Merton model is given by:
\[ \Psi_{X_t}(u) = -\frac{\sigma^2u^2}{2} + i\gamma u + \lambda \left( e^{
\mu_J iu - \frac{\sigma_J^2 u^2}{2}} - 1 \right) \]
Again, thanks to the requirement that the mean must be done under the risk
neutral measure, we have that $\Psi_{X_t}(-i)$ must be equal to $0$. Hence:
\[ \gamma = -\frac{\sigma^2}{2} - \lambda \left( e^{\frac{\sigma^2}{2} + \mu_J}
- 1 \right) \]
After computing the drift we then pass on to the actual simulation in which we
will sample the number of jumps between each time step from a Poisson
distribution with intensity $\lambda \Delta t$ and the continuous part from a
Standard Normal which we will then rescale by $\sigma \sqrt{\Delta t}$.
For each simulation we will sample the jump sizes from a Normal distribution
with mean $\mu_J$ and variance $\sigma_J^2$.
Finally we will sum the jumps and the continuous part to get the simulated
values of the L\'evy process at each time step.

Such a procedure can be implemented into the following Matlab function:

\begin{minted}{matlab}
function X=Merton_Simulation(Nsim,T,params,M)

% parameters and drift
dt=T/M;
X=zeros(Nsim,M+1);
sigma=params(1);
lambda=params(2);
muJ=params(3);
sigmaJ=params(4);
Psi=@(u) -sigma^2*u^2/2+lambda*...
    (exp(-sigmaJ^2*u^2/2+1i*muJ*u)-1);
drift=-Psi(-1i);

% Sample Number of Jumps in each time-bucket
Ndt=icdf('Poisson',rand(Nsim,M),lambda*dt);
% Sample Continuous Component Normal of size Nsim x M
Z=randn(Nsim,M);

% Simulation
for i=1:M % time loop
   % continuous part for the time step (matrix multiplication)
   X(:,i+1)=X(:,i)+drift*dt+sigma*sqrt(dt)*Z(:,i);
   for j=1:Nsim % simulation loop
       if Ndt(j,i)>0 % if there are jumps
           % sample jumps
           Y=sum( muJ+sigmaJ*randn(Ndt(j,i),1) );
           % add jumps
           X(j,i+1)=X(j,i+1)+Y;
       end
   end
end
\end{minted}

If we would like to actually simulate the Stock Price process we would have to
take the exponential of the simulated L\'evy process. We can do it by adding the
initial stock price to the function parameters and then returning the
exponential of the simulated L\'evy process. We modify the function like so:

\begin{minted}{matlab}
function S=Merton_Simulation(Nsim,T,params,M,S0,r)

%% Same code as before ... 

Psi=@(u) -sigma^2*u^2/2+lambda*...
    (exp(-sigmaJ^2*u^2/2+1i*muJ*u)-1);
drift=r-Psi(-1i);

%% Same code as before ...

% get the stock price
S=S0*exp(X);

\end{minted}
\unsure{Why is there the r in the drift?}


\section{Monte Carlo Simulation}

Now that we have developed an implementation for both the Merton and Kou models
to simulate stock prices, how can we use these in order to price options? The
answer lies in Monte Carlo simulation methods. Hence in this lecture we will go
over how to use Monte Carlo simulation methods to price different types of
options, with a strong focus on exotic options. Monte Carlo methods entail doing
multiple simulations of the possible paths of the underlying asset, and then
averaging the results to get the mean of the payoff function conditional on the
underlying asset's price at the start of the simulation.

Unfortunately because the number of simulation to achieve high accuracy is
often fairly large, Monte Carlo methods suffer from a very high computational
overhead.

\section{Theoretical Framework}

First of all, let us understand what are the tools at our disposal.
Let $(\Omega, \mathcal{F}, \mathbb{P})$ be a probability space, and let $X$
be a random variable on this space. Our aim is to estimate its mean $\theta = 
\E[X]$. The easiest unbasied estimator we can construct is the sample mean:
\[ \hat{\theta}_n = \frac{1}{n} \sum_{i=1}^n X_i \]
where $X_i$ are i.i.d. copies of $X$.
Recall that such an estimator has variance:
\[ \Var[\hat{\theta}_n] = \frac{1}{n} \Var[X] \]
Now we will see two crucial theorems relating to the convergence and the
asymptotic distribution of this estimator.

\begin{theorem*}[Law of Large Numbers]
Let $\seq{X}$ be a sequence of i.i.d. random variables with mean $\theta$.
If we define the random variable:
\[ Y(n) = \frac{1}{n} \sum_{i=1}^n X_i \]
then:
\[ \lim_{n\to\infty} \P(|Y(n) - \theta| > \epsilon) = 0 \quad \forall \epsilon
> 0 \]
\end{theorem*}

\begin{theorem*}[Central Limit Theorem]
Let $\seq{X}$ be a sequence of i.i.d. random variables with mean $\theta$ and
variance $\sigma^2$. Then:
\[ \frac{\sum_{i=0}^n X_i - n\theta}{\sigma\cdot\sqrt{n}} = \frac{\hat{\theta}_n
- \theta}{\sigma / \sqrt{n}} \toin{d} \mathcal{N}(0,1) \]
\end{theorem*}

In other words, for a sufficiently large $n$ we have that the distribution of
$\hat{\theta}_n - \theta$, i.e. the MonteCarlo error, is approximately normal
with mean $0$ and variance $\frac{\sigma^2}{n}$:
\[ \hat{\theta}_n - \theta \sim \mathcal{N}\left(0, \frac{\sigma^2}{n}\right) 
\text{ for } n \text{ large enough}\]
This an extremely useful result, because, no matter the distribution of $X$,
we can always rely on the fact that the distribution of the MonteCarlo error
will be normal.
One problem that can arise from not knowing the distribution of $X$ is that we
have no knowledge of the actual variance, so we will use the sample variance
instead:
\[ \hat{\sigma} = \sqrt{\frac{1}{n-1} \sum_{i=1}^n (X_i - \hat{\theta}_n)^2}\]
This is an unbiased estimator of the variance, and it is also consistent.
More in general, we can say the the Monte Carlo method has a
$\mathcal{O}\left(\frac{1}{\sqrt{n}}\right)$ convergence rate.
In other words in order to cut our estimation error in half we need to 
quadruple the number of samples. This is quite inconvenient and computationally
onerous.

This is why we often prefer to use confidence intervals instead of point
estimates. In particular we take two values $a$ and $b$ and estimate the
probability that $\theta$ lies in the interval $[a,b]$.

Recall that from the law of large numbers we have that for $n$ large enough:
\[ \P \left( \frac{\hat{\theta}_n - \theta}{\sigma / \sqrt{n}} \leq x \right)
\approx \Phi(x) \]
where $\Phi$ is the cumulative distribution function of the standard normal.
This means that we can construct a confidence interval for $\theta$ by
inverting the cumulative distribution function:
\[ \P(a < \theta < b) = \P \left( \frac{\hat{\theta}_n - b}{\sigma/\sqrt{n}}
< \frac{\hat{\theta}_n-\theta}{\sigma/\sqrt{n}} < \frac{\hat{\theta}_n-a}
{\sigma/\sqrt{n}} \right) = \Phi(b) - \Phi(-a) \]
\unsure{Ask professor what the passages actually are.}
If we take the choice $a = b = z_{\delta/2}$ where $z_{\delta/2}$ is the
$1-\delta/2$ quantile of the standard normal distribution, we get that:
\[ \P \left( \hat{\theta}_n - z_{\delta/2} \frac{\sigma}{\sqrt{n}} < \theta <
\hat{\theta}_n + z_{\delta/2} \frac{\sigma}{\sqrt{n}} \right) = 1 - \delta \]
This is a $1-\delta$ confidence interval for $\theta$.
Again, we often do not know the actual variance $\sigma^2$, so we will use the
sample variance instead:
\[ \P \left( \hat{\theta}_n - z_{\delta/2} \frac{\hat{\sigma}}{\sqrt{n}} <
\theta < \hat{\theta}_n + z_{\delta/2} \frac{\hat{\sigma}}{\sqrt{n}} \right) =
1 - \delta \]
and we say that the interval:
\[ \left[ \hat{\theta}_n - z_{\delta/2} \frac{\hat{\sigma}}{\sqrt{n}},
\hat{\theta}_n + z_{\delta/2} \frac{\hat{\sigma}}{\sqrt{n}} \right] \]
is an asymptotically valid confidence interval for $\theta$.

\section{Exotic options: refresher}
As we have seen Monte Carlo simulation offer us a very general and powerful
toolbox for estimating means of random variables. But how can we translate this
knowledge into a pricing method for options?

Let us recall that under the assumtpions of the fundamental theorem of asset
pricing, we have that the price of an option is given by the discounted
expected value of its payoff under the risk-neutral measure $\mathbb{Q}$:
\[ V_0 = e^{-rT} \E^\Q \left[ \Phi(S(T)) \right]\]
where $\Phi$ is the payoff function of the option, and $S(T)$ is the price of
the underlying asset at maturity.

Thus we can use Monte Carlo simulations to estimate the price of an option by
simulating the possible paths of the underlying asset, and then averaging the
payoff function over the simulated paths. Or more frequently by estimanting
the $1-\delta$ confidence interval for the price of the option, where $\delta$
usually takes the value $0.05$ or $0.01$.

This methodology is often applied to exotic options, i.e. options whose payoff
function is not a simple function of the underlying asset's price at maturity
but often depends on the whole path of the underlying asset. This makes it
impossible to price these options using analytical methods, and thus Monte
Carlo simulation is often the only viable option.

\subsection*{Asian Options}
Asian options are a class of exotic options whose payoff depends on the average
price of the underlying asset over the whole life of the option. In particular
the average can be calculated as follows:

\begin{itemize}
    \item Arithmetic average: \[ A = \frac{\sum^M_{i+0} S(i\Delta t)}{M+1} \]
    \item Geometric average: \[ A = \Pi_{i=0}^M S(i\Delta t) \]
\end{itemize}

Where $\Delta t$ is the time step of the simulation, and $M$ is the number of
steps. TODO: frequency might be linked to the market convention.
Furthermore Asian options can be divided into two categories depending on the
type of strike price:

\begin{itemize}
    \item Fixed strike: \begin{align*}
        \Phi(S(T)) & = (A - K)^+ \text{ for call options} \\
        \Phi(S(T)) & = (K - A)^+ \text{ for put options}
    \end{align*}
    \item Floating strike: \begin{align*}
    \Phi(S(T)) & = (S(T)-A)^+ \text{ for call options} \\
    \Phi(S(T)) & = (A-S(T))^+ \text{ for put options}
\end{align*}
\end{itemize}

\subsection*{Lookback Options}
Loockback options are another class of exotic options whose payoff depends on
the maximum or minimum price of the underlying asset over the whole life of
the option. In particular, since some of the possible combinations would not be
reasonable to trade, we only find a subset of the possible payoffs on the
market:

\begin{itemize}
    \item Fixed strike: \begin{align*}
        \Phi(S(T)) & = (M - K)^+ \text{ for call options} \\
        \Phi(S(T)) & = (K - m)^+ \text{ for put options}
    \end{align*}
    \item Floating strike: \begin{align*}
        \Phi(S(T)) & = (S(T)-m)^+ \text{ for call options} \\
        \Phi(S(T)) & = (M-S(T))^+ \text{ for put options}
    \end{align*}
\end{itemize}

where $M$ is the maximum price of the underlying asset over the life of the
option, and $m$ is the minimum price of the underlying asset over the life of
the option. Note that these two quantities assume following values in our
computational framework:
\begin{align*}
    M & = \max_i S(i\Delta t) \\
    m & = \min_i S(i\Delta t)
\end{align*}

\subsection*{Barrier Options}
Barrier options are a class of exotic options whose payoff depends on whether
the underlying asset prices has visited a certain region of the state space
during the life of the option, in particular we have Up, Down and Knock options.
Up options have a payoff that depends on whether the underlying asset price has
ever been above a certain threshold, Down options have a payoff that depends on
whether the underlying asset price has ever been below a certain threshold while
Knock options have a payoff that depends on whether the underlying asset price
has ever been above or below a certain threshold. Furthermore barrier options
can be divided into In and Out options depending on whether the payoff is
activated when the underlying asset price enters or leaves the region of the
state space.

Let us summarize these combinations in a table:

\begin{center}
    \begin{tabular}{|c|c|c|c|}
        \hline
        & Up & Down & Knock \\
        \hline
        In & Up and In & Down and In & Knock and In \\
        \hline
        Out & Up and Out & Down and Out & Knock and Out \\
        \hline
    \end{tabular}
\end{center}

Just like for lookback options, we only find a subset of the possible payoffs
on the market due to the reasonableness of the payoff. Let us see a few examples
of barrier options:

\begin{itemize}
    \item Down and Out Call:
        \[ \Phi(S(T)) = (S(T)-K)^+ \cdot \I_{\{ \min_i S(i\Delta t) > b \}}
        \text{ with } S_0 > b \]
    \item Up and In Put:
        \[ \Phi(S(T)) = (K-S(T))^+ \cdot \I_{\{ \max_i S(i\Delta t) \geq u \}}
        \text{ with } S_0 < u \]
    \item Knock and Out Call:
        \[ \Phi(S(T)) = (S(T)-K)^+ \cdot \I_{\{ \min_i S(i\Delta t) > b and
        \max_i S(i\Delta t) \geq u \}} \]
    \item Knock and In Call:
        \[ \Phi(S(T)) = (S(T)-K)^+ \cdot \I_{\{ \min_i S(i\Delta t) \leq b or
        \max_i S(i\Delta t) < u \}} \]
\end{itemize}

\section{Monte Carlo Simulation for Exotic Options (some examples)}
Now that we have had a refresher on exotic options and their respective payoffs,
let us see how we can use Monte Carlo simulation to price them using the Matlab
function that we have developed for the Merton model (we could achieve the same
with the Kou model).



