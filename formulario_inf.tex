\documentclass[a4paper,notitlepage]{report}%imposto la classe la dimensione


\usepackage[T1]{fontenc} % codifica dei font per l'italiano
\usepackage[utf8]{inputenc} % lettere accentate da tastiera
\usepackage[italian]{babel} % lingua del documento
\usepackage[shortlabels]{enumitem}%per fare elenchi ad hoc
\usepackage{amsmath}% per avere le formule matematiche fatte bene
\usepackage{amssymb}% per avere le formule matematiche fatte bene
\usepackage{amsthm}%per fare i teoremi in modo ordinato
\usepackage[big]{layaureo} %per avere i margini più stretti
\usepackage[table]{xcolor}%per colorare le tabelle
\usepackage{framed}% per riquadrare il testo
\usepackage{calrsfs}% per avere le lettere calligrafiche
\usepackage{empheq} %per fare le equazioni per bene
\usepackage{titling}% per modificare il titolo
\usepackage{graphicx} %per inserire le immagini 
\usepackage{dirtytalk}% per mettere più facilmente le virgolette
\usepackage{titlesec}
\usepackage{multicol}
\usepackage{blindtext}
\usepackage{cancel} % per cancellare le espressioni
\setlength{\columnsep}{1cm}


%ridefinisco i set di numeri
\newcommand{\C}{\mathbb{C}}
\newcommand{\N}{\mathbb{N}}%naturali
\newcommand{\R}{\mathbb{R}}%reali
\newcommand{\Z}{\mathbb{Z}} %relativi 
\newcommand{\p}{\mathbb{P}} %probabilità
\newcommand{\E}{\mathbb{E}} %media
\newcommand{\indep}{\perp \!\!\! \perp} %indipendenza
\DeclareMathOperator*{\argsup}{arg\,sup} % argsup

\setlist[itemize]{leftmargin=*}
\setlength\parindent{0pt}


\begin{document}

\chapter*{Formule e Teoremi utili}

\begin{multicols*}{2}

\section*{Probabilità}


    \subsection*{Distribuzione della trasformata}
    Sia $f_X(x)$ e $y=g(x)$.
    \begin{itemize}
        \item Se $g$ crescente: $F_Y(y) = F_X(g^{-1}(y))$
        \item Se $g$ decrescente: $F_Y(y) = 1 - F_X(g^{-1}(y))$
        \item Se $g^{-1}$ derivabile: \\
            $f_Y(y) = f_X(g^{-1}(y)) |\dot{g}^{-1}(y)| $
    \end{itemize}


    \subsection*{Varianza}
    \[
        Var[X] = \E[(X-\E[X])^2] = \E[X^2]-\E[X]^2    
    \]


    \subsection*{Marginali, Congiunte e Condizionate}
    \begin{align*}
        & f_{x,y} = f_{x|y}f_y \\
        & f_x = \int f_{x,y} dy
    \end{align*}


    \subsection*{Media e Varianza Condizionati}
    \begin{align*}
        & \E[X] = \E[\E[X|Y]] \\
        & Var[X] = \E[Var[X|Y]] + Var[\E[X|Y]]
    \end{align*}


    \subsection*{Legge Forte Grandi Numeri}
    Sia $X_1, \dots, X_n$ iid con $\mu, \sigma^2$, allora:\\
    $\bar{X}_n \overset{q.c.}{\to} \mu$


    \subsection*{Teorema centrale del limite}
    Sia $X_1, \dots, X_n$ iid con $\mu, \sigma^2$, allora:\\
    $\sqrt{n}(\bar{X}_n - \mu) \overset{L}{\to} N(0,\sigma^2)$


    \subsection*{Metodo delta}
    Sia $X_1, \dots, X_n$ iid con $\mu, \sigma^2$, tali che:\\
    $\sqrt{n}(\bar{X}_n - \mu) \overset{L}{\to} N(0,\sigma^2)$ \\
    Prendiamo una funzione $g(x)$ e un certo $\theta$:
    \begin{itemize}
        \item Se $g'(\theta)\neq0$: \\
            $\sqrt{n}(g(\bar{X}_n) - g(\mu)) \overset{L}{\to} N(0,\sigma^2g'(\mu)^2)$
        \item Se Se $g'(\theta)=0$: \\
        $\sqrt{n}(g(\bar{X}_n) - g(\mu)) \overset{L}{\to} \frac{\sigma^2}{2} g''(\mu)\chi^2(1)$
    \end{itemize}


\section*{Statistiche sufficienti}


    \subsection*{Definizione}
    Una statistica $T$ è sufficiente per $\theta$ se:\\
    $f(\vec{x}|T=t) \indep \theta \quad \forall t$


    \subsection*{Teorema di Fattorizzazione}
    Data la congiunta $f(\vec{x},\theta)$, $T(x)$ è suff se:\\
    $f(\vec{x},\theta) = h(\vec{x}) g(T(x),\theta)$\\
    Questo vale anche per trasformazioni \textbf{biunivoche} di $T$


    \subsection*{Famiglia Esponenziale}
    Se ho una distribuzione della FE:\\
    $f(\vec{x},\theta) = h(\vec{x}) c(\theta) \exp\left\{ \sum_{i=1}^k w_i(\theta) t_i(x) \right\}$ \\
    Allora $T=(\sum_j t_1(X_j), \dots, \sum_j t_k(X_j) )$ è sufficiente


\section*{Statistiche sufficienti e minimali}


    \subsection*{Definizione}
    Una statistica sufficiente $T$ viene detta minimale
    se tutte le altre statistiche sufficienti sono funzioni
    di essa.


    \subsection*{Lehmann-Scheffè sulla minimalità}
    Sia $f(\vec{x},\theta)$ e $T$ stat suff. $T$ è minimale se:\\
    $\frac{f(\vec{x},\theta)}{f(\vec{y},\theta)}=K$ con $K$ costante
    $\iff$ \\
    $T(x)=T(y)$


\section*{Statistiche complete}


    \subsection*{Definizione}
    Sia $T(x)$ una statistica e $f(t,\theta)$ la sua legge.
    Diciamo $T(x)$ completa se:
    \[
        \E_\theta[g(T)] = 0 \: \forall\theta \implies \p(g(T)=0)=1    
    \]
    Di solito usiamo la derivata rispetto a $\theta$:
    \begin{align*}
        & \frac{d}{d\theta} \E_\theta[g(T)] = 0 \\
        & = h'(\theta) \overset{0}{\cancel{\E_\theta[g(T)]}} + h(\theta)g(t)f_T(t,\theta) \Big|_a^b
    \end{align*}

    
    \subsection*{Teorema di Bahadur}
    Se $T$ è una statistica sufficiente e completa $\implies$ minima


    \subsection*{Famiglia Esponenziale}
    Sia:\\
    $f(\vec{x},\theta) = h(\vec{x}) c(\theta) \exp\left\{ \sum_{i=1}^k w_i(\theta) t_i(x) \right\}$ \\
    Allora $T=(\sum_j t_1(X_j), \dots, \sum_j t_k(X_j) )$ è sufficiente
    ed è completa se il codominio di $w_1,\dots,w_k: \Theta \to \R^k$
    contiene un aperto di $\R^k$.
    
    
\section*{Stimatori Puntuali}


    \subsection*{Metodo dei Momenti}
    \[
        \left\{\begin{array}{l}
            m_1 = \frac{1}{n}\sum_{i=0}^n X_i = \E[X] \\
            \vdots \\
            m_k = \E[X^k]
        \end{array}\right.
    \]
    I momenti saranno funzione di $\theta$, risolvo il sistema lineare
    e trovo $\hat{\theta}_{Mom}$\\
    Il risultato potrebbe non appartenere a $\Theta$


    \subsection*{Metodo della Verosomiglianza}
    Massimizzo la congiunta:\\
    \[
        \hat{\theta}_{MLE} = \argsup_{\theta\in\Theta} L(\theta,\vec{x})
    \]
    Con $L(\theta,\vec{x}) = f(\vec{x},\theta)$, dà sempre valori ammissibili.
    Di solito usiamo:\\
    $\frac{\partial L(\theta,\vec{x})}{\partial \theta} = 0$

        \subsubsection*{Proprietà}
            \textbf{Invarianza}\\
            L'MLE per $\tau(\theta)$ è $\tau(\hat{\theta}_{MLE})$
            per qualsiasi funzione $\tau$


\section*{Scarto quadratico media}


    \subsection*{Definizione}
    $MSE[T] = \E_\theta[(T-\theta)^2]$


    \subsection*{Bias}
    $Bias[T] = \E_\theta[T]-\theta$

    
    \subsection*{Scomposizione}
    $MSE[t] = Var_\theta[T] + Bias[T]^2$


    \subsection*{Stimatore non distorto}
    Uno stimatore $T$ è non distorto se:


\section*{UMVUE}

    \subsection*{Definizione}
    Uno stimatore $T$ è UMVUE se:
    \begin{itemize}
        \item è non distorto: $\E[T]=\theta$
        \item $Var[T] \leq Var[T^*] \quad \forall T^*$ non distorto
    \end{itemize}
    Inoltre l'UMVUE è \textbf{unico}.

    \subsection*{Lehmann-Scheffè per UMVUE}
    Siano $T$ non distorto e $W$ sufficiente e completa (e minima).
    Allora: \\
    $M=\E_\theta[T|W]$ è UMVUE.\\
    E analogamente per una funzione di $\theta$


    \subsection*{UMVUE per $\phi(\theta)$}
    Sia $T$ sufficiente e completa e $\phi(T)$, allora
    $\phi(T)$ è UMVUE per $\E_\theta[\phi(T)]$


    \subsection*{UMVUE per Famiglia Esponenziale}
    Se $X_1,\dots,X_n\in EF$ e: \\
    $f(\vec{x},\theta) = h(\vec{x}) c(\theta) \exp\left\{ w_1(\theta) t_1(x) \right\}$
    Tale che 
    $\exists \frac{d}{d\theta} w(\theta) \neq 0$
    e continua $\forall\theta$. Allora:\\
    $T(X) = \frac{1}{n} \sum_{i=1}^n T_1(X_j)$ è UMVUE
    per $\E_\theta[T_1(X)]$


\section*{Test d'Ipotesi}


    \subsection*{Regione Critica}
    $R= \left\{ \vec{x}\in\R^k | \text{ rifiuto } H_0  \right\}$ \\
    Di solito si basa su una statistica.

        \subsubsection*{Rapporto di Verosimiglianza}
        $R = \{ \vec{x} | \lambda(x) \leq c \}$ con $c\in[0,1]$
        \[
            \lambda(x) = \frac{ \sup_{\Theta_0} L(\theta, x) }{ \sup_{\Theta} L(\theta, x) }    
        \]


    \subsection*{Funzione potenza}
    $\beta(\theta) = \p_\theta(x\in R)$

        \subsubsection*{Dimensione}
        $\alpha = sup_{\Theta_0} \beta(\theta)$

        \subsubsection*{Livello}
        $\alpha \geq sup_{\Theta_0} \beta(\theta)$


    \subsection*{UMP}
    Un test di una classe $C$ è UMP se:\\
    $\beta(\theta)\geq\beta'(\theta) \quad \forall\theta\in\Theta_0^c\quad \forall \beta'\in C$


    \subsection*{Lemma di Neymann-Perason}
    



















\end{multicols*}


\end{document}

























